<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CDI TabMesh ‚Äî In-Browser Inference</title>
    <style>
        :root {
            --bg: #0a0e17;
            --card: #111827;
            --border: #1f2937;
            --accent: #06b6d4;
            --gold: #f59e0b;
            --green: #10b981;
            --red: #ef4444;
            --text: #e5e7eb;
            --dim: #6b7280;
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: 'Inter', system-ui, sans-serif;
            background: var(--bg);
            color: var(--text);
            padding: 20px;
            min-height: 100vh;
        }

        h1 {
            font-size: 1.4rem;
            margin-bottom: 16px;
        }

        h1 span.badge {
            font-size: 0.7rem;
            padding: 3px 8px;
            border-radius: 12px;
            vertical-align: middle;
            margin-left: 8px;
        }

        .badge-e2e {
            background: rgba(6, 182, 212, 0.2);
            color: var(--accent);
        }

        .badge-webgpu {
            background: rgba(16, 185, 129, 0.2);
            color: var(--green);
        }

        .badge-no-webgpu {
            background: rgba(239, 68, 68, 0.2);
            color: var(--red);
        }

        .grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 16px;
            margin-bottom: 16px;
        }

        @media (max-width: 900px) {
            .grid {
                grid-template-columns: 1fr;
            }
        }

        .card {
            background: var(--card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 16px;
        }

        .card h2 {
            font-size: 0.9rem;
            color: var(--dim);
            margin-bottom: 10px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        #nodeInfo {
            display: flex;
            gap: 12px;
            align-items: center;
            flex-wrap: wrap;
        }

        #nodeInfo .stat {
            background: rgba(255, 255, 255, 0.05);
            padding: 6px 12px;
            border-radius: 8px;
            font-size: 0.85rem;
        }

        #nodeInfo .stat b {
            color: var(--accent);
        }

        .btn {
            display: inline-block;
            padding: 8px 18px;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            font-size: 0.85rem;
            transition: all 0.2s;
        }

        .btn-primary {
            background: var(--accent);
            color: #000;
        }

        .btn-primary:hover {
            filter: brightness(1.15);
        }

        .btn-primary:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }

        .btn-gold {
            background: var(--gold);
            color: #000;
        }

        .btn-gold:hover {
            filter: brightness(1.15);
        }

        .btn-gold:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }

        .btn-sm {
            padding: 5px 12px;
            font-size: 0.75rem;
        }

        select,
        input,
        textarea {
            background: rgba(255, 255, 255, 0.07);
            border: 1px solid var(--border);
            border-radius: 8px;
            color: var(--text);
            padding: 8px 12px;
            font-size: 0.85rem;
            width: 100%;
        }

        textarea {
            resize: vertical;
            min-height: 60px;
            font-family: inherit;
        }

        .progress-wrap {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 8px;
            height: 28px;
            overflow: hidden;
            position: relative;
            margin: 8px 0;
        }

        .progress-bar {
            height: 100%;
            background: linear-gradient(90deg, var(--accent), var(--green));
            border-radius: 8px;
            transition: width 0.3s;
            width: 0%;
        }

        .progress-text {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.75rem;
            font-weight: 600;
        }

        .log {
            background: rgba(0, 0, 0, 0.3);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 10px;
            max-height: 200px;
            overflow-y: auto;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.72rem;
            line-height: 1.5;
        }

        .log .ts {
            color: var(--dim);
        }

        .log .e2e {
            color: var(--accent);
        }

        .log .model {
            color: var(--gold);
        }

        .log .err {
            color: var(--red);
        }

        .log .ok {
            color: var(--green);
        }

        .peer-list {
            list-style: none;
        }

        .peer-list li {
            padding: 6px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.05);
            font-size: 0.8rem;
            display: flex;
            gap: 8px;
            align-items: center;
        }

        .peer-badge {
            font-size: 0.65rem;
            padding: 2px 6px;
            border-radius: 6px;
        }

        .peer-badge-e2e {
            background: rgba(6, 182, 212, 0.2);
            color: var(--accent);
        }

        .peer-badge-model {
            background: rgba(245, 158, 11, 0.2);
            color: var(--gold);
        }

        .inference-output {
            background: rgba(0, 0, 0, 0.4);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 12px;
            min-height: 80px;
            font-size: 0.85rem;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .inference-output .cursor {
            display: inline-block;
            width: 8px;
            height: 16px;
            background: var(--accent);
            animation: blink 1s step-end infinite;
            vertical-align: text-bottom;
        }

        @keyframes blink {
            50% {
                opacity: 0;
            }
        }

        .stats-row {
            display: flex;
            gap: 16px;
            margin-top: 8px;
            flex-wrap: wrap;
        }

        .stats-row .stat-pill {
            background: rgba(255, 255, 255, 0.05);
            padding: 4px 10px;
            border-radius: 6px;
            font-size: 0.75rem;
        }

        .stats-row .stat-pill b {
            color: var(--gold);
        }

        .drop-panel {
            background: rgba(239, 68, 68, 0.05);
            border: 1px solid rgba(239, 68, 68, 0.2);
            border-radius: 8px;
            padding: 10px;
            margin-top: 8px;
        }

        .drop-panel h3 {
            font-size: 0.8rem;
            color: var(--red);
            margin-bottom: 6px;
        }

        .controls {
            display: flex;
            gap: 8px;
            align-items: center;
            flex-wrap: wrap;
            margin-bottom: 10px;
        }

        .full-width {
            grid-column: 1 / -1;
        }

        .mt {
            margin-top: 12px;
        }
    </style>
</head>

<body>
    <h1>
        üåê CDI TabMesh ‚Äî In-Browser Inference
        <span class="badge badge-e2e">üîí E2E Encrypted</span>
        <span id="gpuBadge" class="badge badge-no-webgpu">‚è≥ Checking WebGPU‚Ä¶</span>
    </h1>

    <div class="grid">
        <!-- Node Info -->
        <div class="card">
            <h2>‚ö° This Node</h2>
            <div class="controls">
                <button id="btnStart" class="btn btn-primary" onclick="startNode()">üöÄ Start Node</button>
                <span id="nodeStatus" style="font-size:0.8rem; color:var(--dim);">Not started</span>
            </div>
            <div id="nodeInfo">
                <span class="stat">Peer: <b id="myPeerId">‚Äî</b></span>
                <span class="stat">Peers: <b id="peerCount">0</b></span>
                <span class="stat">E2E Keys: <b id="e2eKeys">0</b></span>
                <span class="stat">Model: <b id="loadedModel">none</b></span>
            </div>
        </div>

        <!-- Peers -->
        <div class="card">
            <h2>üë• Network Peers</h2>
            <ul id="peerList" class="peer-list">
                <li style="color:var(--dim);">Start a node to discover peers‚Ä¶</li>
            </ul>
        </div>

        <!-- Model Loading -->
        <div class="card full-width">
            <h2>üß† Model Engine (In-Browser WebGPU)</h2>
            <div class="controls">
                <select id="modelSelect" style="max-width:480px;">
                    <!-- Populated dynamically from SUPPORTED_MODELS -->
                </select>
                <button id="btnLoad" class="btn btn-gold" onclick="loadModel()" disabled>üì• Load Model</button>
                <span id="modelStatus" style="font-size:0.8rem; color:var(--dim);">Start node first</span>
            </div>
            <div class="progress-wrap" id="progressWrap" style="display:none;">
                <div class="progress-bar" id="progressBar"></div>
                <span class="progress-text" id="progressText">0%</span>
            </div>
            <div id="modelMeta"
                style="font-size:0.72rem; color:var(--dim); margin-top:6px; display:flex; gap:12px; align-items:center; flex-wrap:wrap;">
                <span>Models run <b>entirely in your browser</b> via WebGPU. Downloaded once, cached in
                    IndexedDB.</span>
                <span id="vramInfo"></span>
            </div>
        </div>

        <!-- Inference -->
        <div class="card full-width">
            <h2>üí¨ Distributed Inference (E2E Encrypted)</h2>
            <div class="controls">
                <textarea id="promptInput"
                    placeholder="Enter your prompt‚Ä¶ (will be E2E encrypted to the executing node)" rows="2"
                    style="flex:1;"></textarea>
                <button id="btnInfer" class="btn btn-primary" onclick="runInference()" disabled>üîí Send
                    Encrypted</button>
            </div>
            <div id="inferenceOutput" class="inference-output mt" style="display:none;"></div>
            <div class="stats-row" id="inferenceStats" style="display:none;"></div>
        </div>

        <!-- Event Log -->
        <div class="card">
            <h2>üìã Event Log</h2>
            <div id="eventLog" class="log"></div>
        </div>

        <!-- Eavesdropper Drops -->
        <div class="card">
            <h2>üö´ Eavesdropper Drops</h2>
            <div id="dropCount" style="font-size:2rem; font-weight:700; color:var(--red);">0</div>
            <p style="font-size:0.72rem; color:var(--dim); margin-top:4px;">
                Messages this node saw but <b>could NOT decrypt</b> (E2E proof).
            </p>
            <div id="dropLog" class="log mt" style="max-height:120px;"></div>
        </div>
    </div>

    <script type="module">
        import { TabMesh } from './browser/p2p/TabMesh.js';
        import { BrowserInferenceEngine, SUPPORTED_MODELS } from './browser/llm/BrowserInferenceEngine.js';

        // ‚îÄ‚îÄ Globals ‚îÄ‚îÄ
        let mesh = null;
        let engine = null;
        let dropCounter = 0;
        const startTs = Date.now();

        // ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ

        function log(msg, cls = '') {
            const el = document.getElementById('eventLog');
            const ts = ((Date.now() - startTs) / 1000).toFixed(1);
            el.innerHTML += `<div><span class="ts">[${ts}s]</span> <span class="${cls}">${msg}</span></div>`;
            el.scrollTop = el.scrollHeight;
        }

        function logDrop(msg) {
            const el = document.getElementById('dropLog');
            const ts = ((Date.now() - startTs) / 1000).toFixed(1);
            el.innerHTML += `<div><span class="ts">[${ts}s]</span> <span class="err">${msg}</span></div>`;
            el.scrollTop = el.scrollHeight;
        }

        function genPeerId() {
            const arr = new Uint8Array(12);
            crypto.getRandomValues(arr);
            return 'CDI-' + [...arr].map(b => b.toString(16).padStart(2, '0')).join('');
        }

        function updatePeerList() {
            const el = document.getElementById('peerList');
            if (!mesh || mesh.peers.size === 0) {
                el.innerHTML = '<li style="color:var(--dim);">No peers yet‚Ä¶</li>';
                return;
            }
            el.innerHTML = '';
            for (const [id, p] of mesh.peers) {
                const e2eBadge = mesh.e2e.hasPeer(id)
                    ? '<span class="peer-badge peer-badge-e2e">üîí E2E</span>'
                    : '<span class="peer-badge" style="background:rgba(239,68,68,0.2);color:var(--red);">üîì OPEN</span>';
                const modelBadges = (p.models || []).map(m =>
                    `<span class="peer-badge peer-badge-model">üß† ${m.split('-')[0]}</span>`
                ).join(' ');
                el.innerHTML += `<li>${id.slice(0, 16)}‚Ä¶ ${e2eBadge} ${modelBadges}</li>`;
            }
            document.getElementById('peerCount').textContent = mesh.peers.size;
            document.getElementById('e2eKeys').textContent = mesh.e2e.peerCount;
        }

        // ‚îÄ‚îÄ Check WebGPU ‚îÄ‚îÄ
        async function checkGPU() {
            const badge = document.getElementById('gpuBadge');
            if (typeof navigator === 'undefined' || !navigator.gpu) {
                badge.className = 'badge badge-no-webgpu';
                badge.textContent = 'üî¥ No WebGPU';
                return false;
            }
            try {
                const adapter = await navigator.gpu.requestAdapter();
                if (adapter) {
                    badge.className = 'badge badge-webgpu';
                    badge.textContent = 'üü¢ WebGPU';
                    return true;
                }
            } catch { }
            badge.className = 'badge badge-no-webgpu';
            badge.textContent = 'üî¥ No WebGPU';
            return false;
        }
        checkGPU();

        // ‚îÄ‚îÄ Populate Model Selector ‚îÄ‚îÄ
        function populateModels() {
            const select = document.getElementById('modelSelect');
            const tierEmoji = { xs: 'üü¢', s: 'üü°', m: 'üü†', l: 'üî¥', xl: 'üíé' };
            select.innerHTML = '';
            for (const m of SUPPORTED_MODELS) {
                const opt = document.createElement('option');
                opt.value = m.id;
                const vramStr = m.vram < 1000 ? `${m.vram}MB` : `${(m.vram / 1024).toFixed(1)}GB`;
                opt.textContent = `${tierEmoji[m.tier] || ''} ${m.name} (${m.params}, ~${vramStr}) ‚Äî ${m.description}`;
                select.appendChild(opt);
            }
            updateVramInfo();
        }

        function updateVramInfo() {
            const modelId = document.getElementById('modelSelect').value;
            const m = SUPPORTED_MODELS.find(x => x.id === modelId);
            const el = document.getElementById('vramInfo');
            if (m) {
                const vramStr = m.vram < 1000 ? `${m.vram}MB` : `${(m.vram / 1024).toFixed(1)}GB`;
                const tierLabel = { xs: 'Any device', s: 'Mid phones', m: 'Flagships/laptops', l: 'dGPU laptops', xl: 'Desktop/MacBook 8GB+' };
                el.innerHTML = `<b>VRAM: ~${vramStr}</b> ¬∑ ${m.family} ¬∑ ${tierLabel[m.tier] || m.tier}`;
            }
        }

        document.getElementById('modelSelect').addEventListener('change', updateVramInfo);
        populateModels();

        // ‚îÄ‚îÄ Start Node ‚îÄ‚îÄ
        window.startNode = async function () {
            document.getElementById('btnStart').disabled = true;
            document.getElementById('nodeStatus').textContent = 'Starting‚Ä¶';

            const peerId = genPeerId();
            document.getElementById('myPeerId').textContent = peerId.slice(0, 16) + '‚Ä¶';

            mesh = new TabMesh({
                peerId,
                ethAddress: '0x' + peerId.slice(4, 44),
                onPeer: (info) => {
                    log(`Peer discovered: ${info.peerId.slice(0, 16)}‚Ä¶ (E2E: ${info.e2e ? 'üîí' : 'üîì'})`, 'e2e');
                    updatePeerList();
                },
                onPeerLost: (info) => {
                    log(`Peer lost: ${info.peerId.slice(0, 16)}‚Ä¶`, 'err');
                    updatePeerList();
                },
                onInferenceReq: async ({ id, prompt, model, fromPeerId }) => {
                    log(`üì® Inference request received: "${prompt.slice(0, 40)}‚Ä¶"`, 'e2e');

                    if (!engine || !engine.isReady) {
                        log(`‚ö†Ô∏è No model loaded ‚Äî cannot serve inference`, 'err');
                        await mesh.respondInference(id, '[ERROR] No model loaded on this node', fromPeerId);
                        return;
                    }

                    log(`üß† Running in-browser inference (${engine.loadedModel})‚Ä¶`, 'model');
                    try {
                        const result = await engine.generate(prompt, { maxTokens: 128, temperature: 0.7 });
                        log(`‚úÖ Generated ${result.tokensGenerated} tokens @ ${result.tokensPerSecond} tok/s`, 'ok');
                        await mesh.respondInference(id, result.text, fromPeerId);
                    } catch (err) {
                        log(`‚ùå Inference failed: ${err.message}`, 'err');
                        await mesh.respondInference(id, `[ERROR] ${err.message}`, fromPeerId);
                    }
                },
                onEncryptedDrop: (info) => {
                    dropCounter++;
                    document.getElementById('dropCount').textContent = dropCounter;
                    logDrop(`üö´ ${info.reason}: msg ${info.id} from ${info.from?.slice(0, 12)}‚Ä¶ ‚Üí ${info.targetPeerId?.slice(0, 12)}‚Ä¶`);
                },
                onMessage: () => { },
            });

            await mesh.start();

            document.getElementById('nodeStatus').textContent = 'üü¢ Running';
            document.getElementById('btnLoad').disabled = false;
            document.getElementById('modelStatus').textContent = 'Select and load a model';
            log('üöÄ Node started ‚Äî E2E keypair generated', 'ok');
            updatePeerList();
        };

        // ‚îÄ‚îÄ Load Model ‚îÄ‚îÄ
        window.loadModel = async function () {
            if (!mesh) return;

            const hasGPU = await checkGPU();
            if (!hasGPU) {
                log('‚ùå WebGPU not available ‚Äî cannot load model. Use Chrome/Edge.', 'err');
                document.getElementById('modelStatus').textContent = 'üî¥ WebGPU required';
                return;
            }

            const modelId = document.getElementById('modelSelect').value;
            const modelInfo = SUPPORTED_MODELS.find(m => m.id === modelId);

            document.getElementById('btnLoad').disabled = true;
            document.getElementById('modelStatus').textContent = `Loading ${modelInfo.name}‚Ä¶`;
            document.getElementById('progressWrap').style.display = 'block';

            log(`üì• Loading ${modelInfo.name} (${modelInfo.params}, ~${modelInfo.vram}MB VRAM)‚Ä¶`, 'model');

            engine = new BrowserInferenceEngine({
                onStatusChange: (status, detail) => {
                    document.getElementById('modelStatus').textContent = detail || status;
                },
                onProgress: (pct) => {
                    document.getElementById('progressBar').style.width = pct + '%';
                    document.getElementById('progressText').textContent = pct + '%';
                },
            });

            try {
                await engine.init(modelId);

                // Announce model to network
                mesh.loadedModels = [modelId];
                mesh._announce();

                document.getElementById('loadedModel').textContent = modelInfo.name;
                document.getElementById('btnInfer').disabled = false;
                document.getElementById('progressWrap').style.display = 'none';
                log(`‚úÖ ${modelInfo.name} loaded ‚Äî ready for inference`, 'ok');
                updatePeerList();
            } catch (err) {
                log(`‚ùå Model load failed: ${err.message}`, 'err');
                document.getElementById('modelStatus').textContent = 'üî¥ Load failed';
                document.getElementById('btnLoad').disabled = false;
            }
        };

        // ‚îÄ‚îÄ Run Inference ‚îÄ‚îÄ
        window.runInference = async function () {
            const prompt = document.getElementById('promptInput').value.trim();
            if (!prompt) return;

            const outputEl = document.getElementById('inferenceOutput');
            const statsEl = document.getElementById('inferenceStats');
            outputEl.style.display = 'block';
            outputEl.innerHTML = '<span class="cursor"></span>';
            statsEl.style.display = 'none';

            document.getElementById('btnInfer').disabled = true;

            // Check: do we have peers? If yes, send via encrypted mesh.
            // If no peers (or self-inference), run locally.
            const hasPeers = mesh && mesh.peers.size > 0;

            if (hasPeers) {
                // ‚îÄ‚îÄ Distributed: send encrypted to peer ‚îÄ‚îÄ
                const infId = 'inf-' + Date.now();
                const model = engine?.loadedModel || 'SmolLM2-360M-Instruct-q4f16_1-MLC';
                log(`üîí Sending encrypted inference to mesh (model: ${model.split('-')[0]})‚Ä¶`, 'e2e');

                // Listen for the response
                const origHandler = mesh.onMessage;
                const responsePromise = new Promise((resolve) => {
                    mesh.onMessage = (data) => {
                        if (data.type === 'inference:res' && data.id === infId) {
                            resolve(data);
                        }
                        origHandler(data);
                    };
                    // Timeout after 120s
                    setTimeout(() => resolve(null), 120000);
                });

                await mesh.requestInference(infId, prompt, model);

                outputEl.innerHTML = '‚è≥ Waiting for encrypted response from peer‚Ä¶<span class="cursor"></span>';

                const response = await responsePromise;
                mesh.onMessage = origHandler;

                if (response) {
                    const text = response.decryptedText || response.output || '[No response]';
                    outputEl.innerHTML = `<span style="color:var(--accent);">[üîí E2E Decrypted]</span>\n\n${text}`;
                    statsEl.style.display = 'flex';
                    statsEl.innerHTML = `
                        <span class="stat-pill">üì° <b>Mesh relay</b></span>
                        <span class="stat-pill">üîí <b>E2E Encrypted</b></span>
                        <span class="stat-pill">From: <b>${response.peerId?.slice(0, 12) || '?'}‚Ä¶</b></span>
                    `;
                    log(`‚úÖ Received encrypted response from ${response.peerId?.slice(0, 12)}‚Ä¶`, 'ok');
                } else {
                    outputEl.innerHTML = '<span style="color:var(--red);">‚è±Ô∏è Timeout ‚Äî no peer responded in 120s</span>';
                    log('‚ùå Inference timeout', 'err');
                }
            } else {
                // ‚îÄ‚îÄ Local: run on this node ‚îÄ‚îÄ
                if (!engine || !engine.isReady) {
                    outputEl.innerHTML = '<span style="color:var(--red);">Load a model first!</span>';
                    document.getElementById('btnInfer').disabled = false;
                    return;
                }

                log(`üß† Running local in-browser inference‚Ä¶`, 'model');
                try {
                    let tokens = '';
                    const result = await engine.generate(prompt, {
                        maxTokens: 256,
                        temperature: 0.7,
                        onToken: (token) => {
                            tokens += token;
                            outputEl.innerHTML = tokens + '<span class="cursor"></span>';
                        },
                    });

                    outputEl.innerHTML = result.text;
                    statsEl.style.display = 'flex';
                    statsEl.innerHTML = `
                        <span class="stat-pill">Tokens: <b>${result.tokensGenerated}</b></span>
                        <span class="stat-pill">Speed: <b>${result.tokensPerSecond} tok/s</b></span>
                        <span class="stat-pill">Latency: <b>${result.latencyMs}ms</b></span>
                        <span class="stat-pill">Model: <b>${result.model?.split('-')[0]}</b></span>
                        <span class="stat-pill">üß† <b>In-Browser (WebGPU)</b></span>
                    `;
                    log(`‚úÖ Local: ${result.tokensGenerated} tokens @ ${result.tokensPerSecond} tok/s, ${result.latencyMs}ms`, 'ok');
                } catch (err) {
                    outputEl.innerHTML = `<span style="color:var(--red);">‚ùå ${err.message}</span>`;
                    log(`‚ùå Inference failed: ${err.message}`, 'err');
                }
            }

            document.getElementById('btnInfer').disabled = false;
        };
    </script>
</body>

</html>